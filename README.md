# NLP-Fall2019

phase 1: Designing a retrieval system. First step: preprocessing data by normalization, tokenization, deleting stopwords and stemming. Second step: Creating Bigram and Positional models. Third step: compression using gamma code and variable code. Forth step: correcting input query using jaccard metric and edit distance. Fifth step: document retrieval in tf-idf vector representation using Inc-Itc.


phase 2: Implementing KNN and Naive Bayes and applying Random Forest and SVM to classify tf-idf borders generated in the last phase and comparing methods with each other. 


phase 3: Vector representation of text data using tf-idf and word2vec methods and clustering them using k-means, guassian mixture models, hierarchical clustering. Implementing a crawler for Semantic Scholar website. 
